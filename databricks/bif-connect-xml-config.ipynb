{"cells":[{"cell_type":"code","source":["source = 'OSCE'\nxml_veraion = '2.0'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ab65d00d-cc3c-40be-ba96-271d01c2c836"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["poc_folder/xml"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f572e7e-a08e-4362-a9fb-27148cc5033d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["import json,os\nimport pyspark.sql.functions as F\nfrom pyspark.sql.types import StructField, StructType, StringType, ArrayType, LongType, TimestampType, BinaryType, IntegerType, DateType\nfrom datetime import datetime\nimport re\nfrom pyspark.sql import Window"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7f6794b-e521-4534-ad9b-e896d8e4718a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%fs ls /mnt/trendmicrobif/xmlsource"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3741ca7b-7805-47cf-8d7d-6e91cdd27644"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["root = '/dbfs/mnt/trendmicrobif/xmlsource/'\nf_list = [] \nf_dict = {}\nfor fname in os.listdir(root):\n  f_dict['file_name'] = fname\n  f_dict['file_path'] = root + fname\n  f_list.append(f_dict)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dbbc4ef9-1134-4801-92f6-51a2ab47cd7f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def read_xml_file(path):\n  with open(path, 'r' ) as f:\n    xml_str = f.read()\n  return xml_str\n\nread_xml_file_udf = udf(read_xml_file, StringType())\n\nfile_info_schema = StructType([\n    StructField('file_date', DateType(), True),\n    StructField('xml_version', StringType(), True),\n    StructField('ip', StringType(), True)\n  \n])\n\ndef file_name_split(path):\n  file_info = {}\n  list = path.split('_')\n  file_info['file_date'] =  datetime.strptime(list[1], \"%Y%m%d%H%M%S%f\")\n  file_info['xml_version'] = list[2]\n  file_info['ip'] = list[3]\n  return file_info\n\nfile_name_split_udf = udf(file_name_split, file_info_schema)\n\n  "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d5c5d6a0-5ee2-4e6e-9ece-ce8bce67f25f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["file_rdd = spark.sparkContext.parallelize(f_list)\nfile_df = (spark.createDataFrame(file_rdd)\n          .select('file_name', read_xml_file_udf('file_path').alias('file_content'))\n          .withColumn('file_info',file_name_split_udf('file_name'))\n          .select('file_info.*','file_name','file_content')\n          )\n\ndisplay(file_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6ec84266-eef1-485e-b9ab-f5d35cafe91d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# get raw data\nwith open(\"/dbfs//mnt/trendmicrobif/TBL_DATA_RAW.json\", \"r\") as f:\n    raw_str = f.read()\nraw_json = json.loads(raw_str)\nraw_array = raw_json[0]['data']\nraw_schema = raw_json[0]['schema']\n\ndef string_to_date(x): \n  return datetime.strptime(x.split('.')[0], \"%Y-%m-%dT%H:%M:%S\")\n\nstring_to_date_udf = udf(string_to_date, DateType())\n\n# Create StructType\nraw_schema = StructType([\n    StructField('file_id', StringType(), True),\n    StructField('source', StringType(), True),\n    StructField('xml_version', StringType(), True),\n    StructField('file_name', StringType(), True),\n  StructField('file_content', StringType(), True),\n  StructField('file_date', StringType(), True),\n  StructField('ip', StringType(), True)\n])\nrdd = spark.sparkContext.parallelize(raw_array)\n\n# Create DataFrame\ndf_raw = (spark.createDataFrame(rdd,raw_schema)\n          .withColumn('file_date', string_to_date_udf(F.col('file_date')))\n          .write.format('delta')\n          .mode('overwrite')\n          .save('/mnt/trendmicrobif/TBL_DATA_RAW')\n         )\ndisplay(df_raw)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"02953e89-4510-4dd7-ae75-af3c700c7925"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_raw = (spark.read.format('delta')\n          .load('/mnt/trendmicrobif/TBL_DATA_RAW')\n          .filter(F.col('source') == source)\n          .filter(F.col('xml_version') == xml_veraion )\n     )\ndf_raw.createOrReplaceTempView('TBL_DATA_RAW')\ndisplay(df_raw)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1323f243-0966-41a0-8837-3ea4de8ba464"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_xpath = (spark.read.format('csv')\n         .option('header', True)\n         .load('/mnt/trendmicrobif/TBL_RAW_XPATH.csv')\n         .filter(F.col('source') == source)\n         .filter(F.col('xml_version') == xml_veraion)\n         \n        )\ndf_config = (spark.read.format('csv')\n         .option('header', True)\n         .load('/mnt/trendmicrobif/TBL_XML_RAW_CONFIG.csv')\n         .filter(F.col('source') == source)\n         .filter(F.col('xml_version') == xml_veraion)\n         \n        )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2c74e118-e746-4e81-96bf-2977ec63c30e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#get config\ndf_xpath_config = (df_xpath.alias('r').join(df_config.alias('c'), [F.col('r.source')==F.col('c.source'),\n                                                                F.col('r.xml_version')==F.col('c.xml_version'),\n                                                                F.col('r.xpath')==F.col('c.xpath')\n                                                               ], 'left')\n                  .withColumn('level', F.coalesce('c.level',F.lit('0')))\n                  .withColumn('raw_group_root', F.coalesce('c.raw_group_root','r.xpath'))\n                  .withColumn('group_root', F.coalesce('c.group_root','r.xpath'))\n                  .withColumn('master_detail', F.coalesce('c.master_detail',F.lit('M')))\n                  .withColumn('column_name', F.coalesce('c.default_column_name','r.xpath'))\n                  .withColumn('data_type', F.coalesce('c.default_data_type',F.lit('varchar')))\n                  .withColumn('data_length', F.coalesce('c.default_data_length',F.lit('1000')))\n                  .withColumn('sample_value', F.coalesce('c.sample_value',F.lit('')))\n                  .withColumn('ID', F.row_number().over(Window.orderBy(F.col('r.source'),F.col('r.xml_version'),F.col('r.xpath'))))\n                  .select('ID', 'r.source', 'r.xml_version', 'level', 'r.xpath', 'raw_group_root', 'group_root', 'master_detail', 'column_name', 'data_type', 'data_length', 'sample_value')\n                  )\ndisplay(df_xpath_config)  "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4ce7e368-f70c-4e0c-8052-fa3a93d5f41b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["data = [('test_data','<data><product_info><hardware_info><cpu>Intel(R) Xeon(R) Gold 5220 CPU @ 2.20GHz x 1 core(s)</cpu><cpu>Intel(R) Xeon(R) Gold 5220 CPU @ 2.20GHz x 1 core(s)</cpu><hdd_partitions><filestores><avail>175981248</avail><size>197460232</size></filestores><varlog><avail>64712540</avail><size>103212320</size></varlog></hdd_partitions><hdd_size>314572800</hdd_size></hardware_info></product_info></data>')]\ndf = spark.createDataFrame(data,[\"file_name\",\"file_content\"])\ndf.createOrReplaceTempView('testdata')\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b7abe13b-48f2-4d6b-9a38-6a09ee62347d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql \nselect file_name,xpath(file_content, '/data/product_info/hardware_info/cpu/text()') from testdata"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"74883ca5-ddc1-4a39-b7d6-9f6ca68af58e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- select b.file_id, xpath(b.file_content,'/Data/Products/Product/Server/LogMaintenance/ScheduleDelete/ScheduledDeleteItems/Item/ByCount/text()') as value from TBL_DATA_RAW b\nselect b.file_id, xpath(b.file_content,'/Data/Products/Product/Server/LogMaintenance/ScheduleDelete/ScheduledDeleteItems/Item/@ByCount') as value from TBL_DATA_RAW b"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"93238047-f2c1-4b61-a600-d5fd34a65fd4"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def list_to_lenght(list): \n  return len(list)\nlist_to_lenght_udf = udf(list_to_lenght, IntegerType())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db406208-308d-4d98-a4ca-bd77c2dade48"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# update master_detail, raw_group_root, group_root, level, column_name\nupdate_set = []\nfor row in df_xpath_config.collect():\n    xpath = row.xpath #/Data/Products/Product/Server/LogMaintenance/ScheduleDelete/ScheduledDeleteItems/Item/@ByCount\n    xpath_list = xpath.split('/')\n    xpath_full_text = '/'.join(xpath_list[:-1])+'/'+xpath_list[-1].replace('@','') +'/text()' #/Data/Products/Product/Server/LogMaintenance/ScheduleDelete/ScheduledDeleteItems/Item/ByCount/text()\n    xpath_full = '/'.join(xpath_list[:-1])+'/@'+xpath_list[-1].replace('@','')  #/Data/Products/Product/Server/LogMaintenance/ScheduleDelete/ScheduledDeleteItems/Item/@ByCount\n    group_root = '/'.join(xpath_list[:-2])+'/'+xpath_list[-2] #/Data/Products/Product/Server/LogMaintenance/ScheduleDelete/ScheduledDeleteItems/Item\n   \n    \n    update_dict = {}\n    if(row.level == '0'):\n      master_detail = 'M'\n      sql_script = f\"select file_id, xpath(file_content,'{xpath_full}') as value from TBL_DATA_RAW\"\n      xpath_tmp = (spark\n                   .sql(sql_script)\n                   .select('file_id', list_to_lenght_udf('value').alias('count'))\n                   .filter(F.col('count')>1)\n                   )\n      if(xpath_tmp.count() > 0): \n        master_detail = 'D'\n        update_dict['ID'] = row.ID\n        update_dict['xpath'] = xpath\n        update_dict['raw_group_root'] = group_root\n        update_dict['master_detail'] = master_detail\n        update_set.append(update_dict)\n      else:\n        sql_script = f\"select file_id, xpath(file_content,'{xpath_full_text}') as value from TBL_DATA_RAW\"\n        xpath_tmp = (spark\n                     .sql(sql_script)\n                     .select('file_id', list_to_lenght_udf('value').alias('count'))\n                     .filter(F.col('count')>1)\n                     )\n        if(xpath_tmp.count() > 0): \n          master_detail = 'D'\n          update_dict['ID'] = row.ID\n          update_dict['xpath'] = xpath\n          update_dict['raw_group_root'] = xpath\n          update_dict['master_detail'] = master_detail\n\n          update_set.append(update_dict)\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4aa0c08c-b911-4318-8f7e-5a508db8216d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def xpath_to_level(xpath): \n  return len(xpath.split('/'))-1\n\nxpath_to_level_udf = udf(xpath_to_level, IntegerType())\n\ndef xpath_to_columnname(xpath): \n  xpath_list = xpath.split('/')\n  return xpath_list[-1].replace('@','')\n\nxpath_to_columnname_udf = udf(xpath_to_columnname, StringType())\n\n\nupdate_rdd= spark.sparkContext.parallelize(update_set)\nupdate_df = (spark\n             .createDataFrame(update_rdd)\n             .withColumn('level',xpath_to_level_udf('xpath'))\n             .withColumn('column_name',xpath_to_columnname_udf('xpath'))\n            )\n\n\ndisplay(update_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"312533a3-c0e3-400b-a7c7-c68dd2d620dd"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_xpath_config_1 = (df_xpath_config.alias('con').join(update_df.alias('update'), F.col('update.ID')==F.col('con.ID'),'left')\n             .withColumn('level1',F.when(F.col('update.level').isNull(), F.col('con.level')).otherwise(F.col('update.level')))\n             .withColumn('master_detail1', F.when(F.col('update.master_detail').isNull(), F.col('con.master_detail')).otherwise(F.col('update.master_detail')))\n             .withColumn('column_name1',F.when(F.col('update.column_name').isNull(), F.col('con.column_name')).otherwise(F.col('update.column_name')))\n             .withColumn('raw_group_root1', F.when(F.col('update.raw_group_root').isNull(), F.col('con.raw_group_root')).otherwise(F.col('update.raw_group_root')))\n             .withColumn('group_root1', F.col('raw_group_root1'))\n             .select('con.ID', 'con.source', 'con.xml_version', 'level1', 'con.xpath', 'raw_group_root1', 'group_root1', 'master_detail1', 'column_name1', 'con.data_type', 'con.data_length', 'con.sample_value')\n              .withColumnRenamed('master_detail1', 'master_detail')\n              .withColumnRenamed('raw_group_root1', 'raw_group_root')\n              .withColumnRenamed('level1', 'level')\n              .withColumnRenamed('group_root1', 'group_root')\n              .withColumnRenamed('column_name1', 'column_name')\n  )\n\ndisplay(df_xpath_config_1)\n#         .filter(F.col('ID')=='399'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c73f530-c044-4604-bbfb-fe9ef034e0d4"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(df_xpath_config.filter(F.col('ID')=='299'))\ndisplay(df_xpath_config_1.filter(F.col('ID')=='299'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e57d036e-4fdc-4ddd-9ffb-bcc40a9871bc"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# update sample_data , data_type ,data_length\n\nupdate_set = []\nfor row in df_xpath_config_1.collect():\n    xpath = row.xpath #/Data/Products/Product/Server/LogMaintenance/ScheduleDelete/ScheduledDeleteItems/Item/@ByCount\n    xpath_list = xpath.split('/')\n    xpath_full_text = '/'.join(xpath_list[:-1])+'/'+xpath_list[-1].replace('@','') +'/text()' #/Data/Products/Product/Server/LogMaintenance/ScheduleDelete/ScheduledDeleteItems/Item/ByCount/text()\n    xpath_full = '/'.join(xpath_list[:-1])+'/@'+xpath_list[-1].replace('@','')  #/Data/Products/Product/Server/LogMaintenance/ScheduleDelete/ScheduledDeleteItems/Item/@ByCount\n    group_root = '/'.join(xpath_list[:-2])+'/'+xpath_list[-2] #/Data/Products/Product/Server/LogMaintenance/ScheduleDelete/ScheduledDeleteItems/Item\n\n    update_dict = {}\n    if(not row.sample_value):\n    \n      sql_script = f\"select file_id, xpath(file_content,'{xpath_full}') as value from TBL_DATA_RAW\"\n      xpath_tmp = (spark\n                   .sql(sql_script)\n                   .select('file_id', 'value',list_to_lenght_udf('value').alias('count'))\n                   .filter(F.col('count')>1)\n                   .select('file_id', F.explode('value').alias('value'))\n                   )\n      \n\n      if(xpath_tmp.count() > 0): \n        update_dict['ID'] = row.ID\n        update_dict['xpath'] = xpath\n        update_dict['sample_value'] = xpath_tmp.rdd.collect()[0][1] \n        update_set.append(update_dict)\n    else:\n      sql_script = f\"select file_id, xpath(file_content,'{xpath_full_text}') as value from TBL_DATA_RAW\"\n      xpath_tmp = (spark\n                   .sql(sql_script)\n                   .select('file_id', 'value',list_to_lenght_udf('value').alias('count'))\n                   .filter(F.col('count')>1)\n                   .select('file_id', F.explode('value').alias('value'))\n                   )\n      if(xpath_tmp.count() > 0): \n        master_detail = 'D'\n        update_dict['ID'] = row.ID\n        update_dict['xpath'] = xpath\n        update_dict['sample_value'] = xpath_tmp.rdd.collect()[0][1] \n        update_set.append(update_dict)\n        "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"37d690ec-5f02-4197-98a5-9ebaba5d1b91"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def is_number(num):\n  pattern = re.compile(r'^[-+]?[-0-9]\\d*\\.\\d*|[-+]?\\.?[0-9]\\d*$')\n  result = pattern.match(num)\n  if result:\n    return True\n  else:\n    return False\n  \ndef is_valid_data(str):\n  try:\n    if \":\" in str:\n      time.strptimr(str,\"%Y-%m-%d %H:%M%:S\")\n    else:\n      time.strptimr(str,\"%Y-%m-%d\")\n    return True\n  except:\n    return False\n  \ndata_schema = StructType([\n    StructField('data_type', StringType(), True),\n    StructField('data_length', StringType(), True)\n])\n\ndef setDatatype(value):\n  data_type = ''\n  data_length = ''\n  data_info = {}\n  if(len(value)>8 and is_valid_data(value)):\n      data_type = \"datetime\"\n      data_length = \"\"\n  elif(is_number(value)):\n    \n    whole_part =  len(str(value).split(\".\")[0])\n    decimal_part = 0\n    if (len(str(value).split(\".\")) == 2) :     \n      decimal_part = len(str(value).split(\".\")[1])\n      \n    if(decimal_part == 0 ):\n      data_type = \"int\"\n      data_length = \"\"\n    else:\n      datatype = \"numeric\"\n      data_length = f\"{str(whole_part+decimal_part)},{decimal_part}\"\n  else:\n    data_type = \"varchar\"    \n    data_length = len(value)\n    \n  data_info['data_type'] = data_type\n  data_info['data_length'] = data_length                     \n  return data_info\n                     \nsetDatatype_udf = udf(setDatatype,data_schema)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9bf96686-c104-4988-ac2f-c76e626aa4a5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["update_rdd= spark.sparkContext.parallelize(update_set)\nupdate_df = (spark\n             .createDataFrame(update_rdd)\n             .withColumn('data_info', setDatatype_udf('sample_value'))\n             .select('ID','xpath','sample_value','data_info.*')\n            )\n\n\ndisplay(update_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e4ed57b-0681-477b-b6c5-a2a5a1e47378"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_xpath_config_2 = (df_xpath_config_1.alias('con').join(update_df.alias('update'), F.col('update.ID')==F.col('con.ID'),'left')\n             .withColumn('sample_value1',F.when(F.col('update.sample_value').isNull(), F.col('con.sample_value')).otherwise(F.col('update.sample_value')))\n             .withColumn('data_type1', F.when(F.col('update.data_type').isNull(), F.col('con.data_type')).otherwise(F.col('update.data_type')))\n             .withColumn('data_length1',F.when(F.col('update.data_length').isNull(), F.col('con.data_length')).otherwise(F.col('update.data_length')))\n             .select('con.ID', 'con.source', 'con.xml_version', 'con.level', 'con.xpath', 'con.raw_group_root', 'con.group_root', 'con.master_detail', 'con.column_name', 'data_type1', 'data_length1', 'sample_value1')\n              .withColumnRenamed('data_type1', 'data_type')\n              .withColumnRenamed('data_length1', 'data_length')\n              .withColumnRenamed('sample_value1', 'sample_value')\n\n  )\n\ndisplay(df_xpath_config_2)\n#         .filter(F.col('ID')=='299'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4dec4d5-f114-4844-83a6-c18d1a10d5dd"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(df_xpath_config.filter(F.col('ID')=='299'))\ndisplay(df_xpath_config_1.filter(F.col('ID')=='299'))\ndisplay(df_xpath_config_2.filter(F.col('ID')=='299'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5ca5803-54b2-40b8-9ab7-2f8ce003bd79"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(df_xpath_config_2)\ndf_xpath_config_2.write.saveAsTable('df_xpath_config_2', mode='overwrite')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"85a6c897-c950-4be7-8af1-aba59e37ca12"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# sql_script = \"select b.file_id, xpath(b.file_content,'/Data/Products/Product/Server/LogMaintenance/ScheduleDelete/ScheduledDeleteItems/Item/@ByCount') as value from TBL_DATA_RAW b\"\n# xpath_tmp = (spark\n#                .sql(sql_script)\n#                .select('file_id', 'value',list_to_lenght_udf('value').alias('count'))\n#                .filter(F.col('count')>1)\n#                .select('file_id', F.explode('value').alias('sample_value'))\n#                .withColumn('data_info', setDatatype_udf('sample_value'))\n#                .select('file_id','sample_value','data_info.*')\n#              )\n\n# display(xpath_tmp)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a0279166-57de-49a0-afb7-5a5e68e41472"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"bif-connect-xml-config","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1310704823771867}},"nbformat":4,"nbformat_minor":0}
